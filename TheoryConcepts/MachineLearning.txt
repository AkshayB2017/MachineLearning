Understanding Machine Learning- Theory to Algorithms

Chapter 1

Bait Shyness- Rats Learning to Avoid Poisonous Baits: Rats eat small amounts of new food items and if there is an ill effect associated with it, rats will avoid it. Animals use past experience to acquire expertise in detecting safety of food.

This can be applied in email-spam labelling question, but here the question is how will the spam detector react to a new, unique case which was not part of the training set.

A successful learner should be able to progress from individual
examples to broader generalization. This is also referred to as inductive reasoning
or inductive inference.

Pigeon Superstition- Consider a bunch of hungry pigeons in a cage. Food was delivered to the pigeons without reference to their behaviour. Each bird started reinforcing the action that they did when they got the food and kept repeating in the expectation of food ariving. Which is not useful learning.

Bait Shyness 2- Due to previous knowledge, the birds were able to realise that there is no correlation between eating food and getting electic shock despite the fact that birds got electric shock when they consumed food. This concept is inductive bias.

When do we need Machine Learning?

1. Task to be done is too complex
   a. Tasks performed by humans
         Driving, Speech Recognition, Image Understanding
   b. Tasks beyond human capabilities
            astronomical data, turning medical archives into medical knowledge, weather prediction, analysis of genomic data, Web search engines, and electronic commerce.

One limiting feature of programmed tools is their rigidity – once the program has been written down and installed, it stays unchanged. However, many tasks change over time or from one user to another.
Machine learning tools – programs whose behavior adapts to their input data – offer a solution to such issues; they are, by nature, adaptive to changes in the environment they interact with.

The first distinction to note is the difference between supervised and unsupervised learning.
 Consider the task of learning to detect spam e-mail versus the task of anomaly detection. For the spam detection task, we consider a setting in which the learner receives training e-mails for which the label spam/not-spam is provided. On the basis of such training the learner should figure out a rule for labeling a newly arriving e-mail message. In contrast, for the task of anomaly detection, all the learner gets as training is a large body of e-mail messages (with no labels) and the learner’s task is to detect “unusual” messages.

 We distinguish between “active” and “passive” learners. An active learner interacts with the environment at training time, say, by posing queries or performing experiments, while a passive learner only observes the information provided by the environment (or the teacher) without influencing or directing it.

When one thinks about human learning, of a baby at home or a student at school, the process often involves a helpful teacher, who is trying to feed the learner with the information most useful for achieving the learning goal. In contrast, when a scientist learns about nature, the environment, playing the role of the teacher, can be best thought of as passive – apples drop, stars shine, and the rain falls without regard to the needs of the learner. We model such learning scenarios by postulating that the training data (or the learner’s experience )is generated by some random process. This is the basic building block in the branch of “statistical learning.” Finally, learning also occurs when the learner’s input is generated by an adversarial “teacher.”

The distinction between situations in which the learner has to respond online, throughout the learning process, and settings in which the learner has to engage the acquired expertise only after having a chance to process large amounts of data.



--------------------------------------------------------------------------------------------------------------------------------------------------

Chapter 2

The learner’s input: In the basic statistical learning setting, the learner has access to the following:
– Domain set: An arbitrary set, X . This is the set of objects that we may wish to label. For example, in the papaya learning problem mentioned before, the domain set will be the set of all papayas. Usually, these domain points will be represented by a vector of features (like the papaya’s color and softness). We also refer to domain points as instances and to X as instance space.
– Label set: We can restrict the label set to be a two-element set, usually {0, 1} or {−1, +1}. Let Y denote our
set of possible labels. For our papayas example, let Y be {0, 1}, where 1 represents being tasty and 0 stands for being not-tasty.
– Training data: S = ((x 1 , y 1 ) . . . (x m , y m )) is a finite sequence of pairs in X × Y: that is, a sequence of labeled domain points. This is the input that the learner has access to (like a set of papayas that have been tasted and their color, softness, and tastiness). Such labeled examples
are often called training examples. We sometimes also refer to S as a training set.

The learner’s output: The learner is requested to output a prediction rule, h : X → Y. This function is also called a predictor, a hypothesis, or a classifier. The predictor can be used to predict the label of new domain points. In our papayas example, it is a rule that our learner will employ to predict whether future papayas he examines in the farmers’ market are going to be tasty or not. We use the notation A(S) to denote the hypothesis that a learning algorithm, A, returns upon receiving the training sequence S.
• A simple data-generation model We now explain how the training data is generated. First, we assume that the instances (the papayas we encounter)
are generated by some probability distribution (in this case, representing the environment). Let us denote that probability distribution over X by
D.  As to the labels, we assume that there is some “correct” labeling function. The labeling function is unknown to the learner. In fact, this is just what the learner is trying to figure out. In summary, each pair in the training data S is generated by first sampling a point x i according to D and then labeling it by f .
• Measures of success: We define the error of a classifier to be the probability that it does not predict the correct label on a random data point generated by the aforementioned underlying distribution. That is, the error of h is the probability to draw a random instance x, according to the distribution D, such that h(x) does not equal f (x).



